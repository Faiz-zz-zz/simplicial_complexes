{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from filenames import COMPLEX_BETWEENNESS, COMPLEX_CLOSENESS, COMPLEX_DEGREE, \\\n",
    "    GENE_ID_CONVERSION\n",
    "from go_script import generate_matrix\n",
    "from itertools import chain\n",
    "from itertools import combinations\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "measures = [\"betweenness\", \"closeness\", \"degree\"]\n",
    "\n",
    "name_map = {\n",
    "    COMPLEX_BETWEENNESS: \"betweenness_centrality\",\n",
    "    COMPLEX_CLOSENESS: \"closeness_centrality\",\n",
    "    COMPLEX_DEGREE: \"degree_centrality\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1, len(s)+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_actual_map():\n",
    "    data = open(\"convertor.txt\").read().split('\\n')\n",
    "    m = {}\n",
    "    for each in data[1:]:\n",
    "        try:\n",
    "            gene_id, gene_symbol, _ = each.split('\\t')\n",
    "            m[gene_symbol] = gene_id\n",
    "        except:\n",
    "            pass\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_json(measure):\n",
    "    measure_map = defaultdict(list)\n",
    "    data = json.loads(open(measure).read())\n",
    "    for dp in data:\n",
    "        for node in dp[\"nodes\"]:\n",
    "            measure_map[node].append(dp[name_map[measure]])\n",
    "\n",
    "    measure_map = dict(list(map(lambda k: (k[0], max(k[1])), list(measure_map.items()))))\n",
    "    data_ppi = json.loads(open(measure.replace(\".json\", \"_PPI.json\")).read())\n",
    "    for data in measure_map:\n",
    "        data_ppi[data] = measure_map[data]\n",
    "    return data_ppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_measure_matrix():\n",
    "    measure_map = {\n",
    "        \"betweenness\": COMPLEX_BETWEENNESS,\n",
    "        \"closeness\": COMPLEX_CLOSENESS,\n",
    "        \"degree\": COMPLEX_DEGREE\n",
    "    }\n",
    "    gene_id_converter = get_actual_map()\n",
    "    matrix, gene_list, go_ids = generate_matrix()\n",
    "\n",
    "    measure_matrix = []\n",
    "    for measure in measure_map:\n",
    "        gene_measure = parse_json(measure_map[measure])\n",
    "        gene_measure_list = []\n",
    "        for gene in gene_list:\n",
    "            try:\n",
    "                gene_measure_list.append(gene_measure[gene_id_converter[str(gene)]])\n",
    "            except:\n",
    "                gene_measure_list.append(0)  # me sorry\n",
    "        measure_matrix.append(gene_measure_list)\n",
    "    return matrix, measure_matrix, go_ids, gene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_regression():\n",
    "    for measure in measures:\n",
    "        matrix, measures, _, _ = generate_measure_matrix(measure)\n",
    "        go_measures = matrix[0]\n",
    "        # print(len(go_measures), len(measures), \"SUP SUP SUP\")\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(np.asarray(measures_list), go_measures)\n",
    "        print(\"Coefficient of determination for {}: {}\".format(measure, r_value ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_multifit():\n",
    "    measures = [\"betweenness\", \"closeness\", \"degree\"]\n",
    "    measure_combs = powerset(measures)\n",
    "    matrix, measure_list, _ = generate_measure_matrix()\n",
    "    measure_dict = {}\n",
    "    for i, measure in enumerate(measures):\n",
    "        measure_dict[measure] = measure_list[i]\n",
    "\n",
    "    for measure_comb in measure_combs:\n",
    "        print(\"Calculating coeff for {}:\".format(\" and \".join(measure_comb)))\n",
    "        X = []\n",
    "        for measure in measure_comb:\n",
    "            X.append(measure_dict[measure])\n",
    "        X = np.asarray(X).T\n",
    "        Y = matrix[0]\n",
    "        clf = linear_model.LinearRegression()\n",
    "        clf.fit(X, Y)\n",
    "        print(\"Coeff is: {}\".format(clf.score(X, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def get_model(train_data):\n",
    "    measure_combs = powerset([0, 1, 2])\n",
    "    Y, *centralities = train_data\n",
    "    models = []\n",
    "    for input_nums in measure_combs:\n",
    "        X = []\n",
    "        for i in input_nums:\n",
    "            X.append(centralities[i])\n",
    "        X = np.asarray(X).T\n",
    "        clf = LogisticRegression()\n",
    "        X_shuffled, Y_shuffled = shuffle(X, Y)\n",
    "        clf.fit(X, Y)\n",
    "        models.append((clf, input_nums))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zip_measure_with_go(measure_matrix, go_matrix):\n",
    "\n",
    "    list_measure_go = []\n",
    "    for go_id in go_matrix:\n",
    "        list_measure_go.append(list(zip(go_id, measure_matrix)))\n",
    "\n",
    "    return list_measure_go\n",
    "\n",
    "def remove_all_test_genes(index_list, go_id_to_measure_map):\n",
    "    test_data = []\n",
    "    for idx in index_list:\n",
    "        test_data.append(go_id_to_measure_map[idx])\n",
    "        go_id_to_measure_map.remove(idx)\n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model_input(gene_data):\n",
    "    data = []\n",
    "    for i in range(4):\n",
    "        data.append(list(map(lambda k: k[i], gene_data)))\n",
    "    return data\n",
    "\n",
    "def build_prediction_data(idx, test_data):\n",
    "    go_id_data = test_data.index(idx)\n",
    "    prediction_data = build_model_input(go_id_data)\n",
    "    return prediction_data\n",
    "\n",
    "\n",
    "def predict_lin_regression():\n",
    "    go_matrix, measure_matrix, go_ids, gene_list = generate_measure_matrix()\n",
    "    predictions = {}\n",
    "    zero_class, total = 0, 0\n",
    "    for ind, go_id in enumerate(go_matrix):\n",
    "        train_data, test_data = train_test_split(list(zip(go_id, measure_matrix[0], measure_matrix[1], measure_matrix[2])), test_size=0.2)\n",
    "        input_data = build_model_input(train_data)\n",
    "        pred_data = build_model_input(test_data)\n",
    "        if not sum(input_data[0]): continue\n",
    "        models = get_model(input_data)\n",
    "        go_id_models_pred = {}\n",
    "        for model in models:\n",
    "            # Ignore trainings with only one class.\n",
    "            model, centralities = model\n",
    "            model_cent_pred = []\n",
    "            pred_input = []\n",
    "            for c in centralities:\n",
    "                pred_input.append(pred_data[c + 1])\n",
    "            pred_input = np.asarray(pred_input).T\n",
    "            pred = model.predict(pred_input)\n",
    "            go_id_models_pred[tuple(centralities)] = {\"prediction\": pred, \"rms\": model.score(pred_input, pred_data[0])}\n",
    "        predictions[go_ids[ind]] = go_id_models_pred\n",
    "    print(\"{}/{}\".format(zero_class, total))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:1: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if __name__ == '__main__':\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:15: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,41) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/100\n"
     ]
    }
   ],
   "source": [
    "a = predict_lin_regression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
